{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Your First AI Agent: From Prompt to Action\n",
    "\n",
    "**Welcome to the Kaggle 5-day Agents course!**\n",
    "\n",
    "This notebook is your first step into building AI agents. An agent can do more than just respond to a prompt ‚Äî it can **take actions** to find information or get things done.\n",
    "\n",
    "In this notebook, you'll:\n",
    "\n",
    "- ‚úÖ Install [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n",
    "- ‚úÖ Configure your API key to use the Gemini model\n",
    "- ‚úÖ Build your first simple agent\n",
    "- ‚úÖ Run your agent and watch it use a tool (like Google Search) to answer a question\n",
    "\n",
    "**‚ÑπÔ∏è Note: No submission required!**\n",
    "\n",
    "This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Get started with Kaggle Notebooks\n",
    "\n",
    "If this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n",
    "\n",
    "Here's how to get started:\n",
    "\n",
    "**1. Verify Your Account (Required)**\n",
    "\n",
    "To use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n",
    "\n",
    "You can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n",
    "\n",
    "**2. Make Your Own Copy**\n",
    "\n",
    "To run any code in this notebook, you first need your own editable copy.\n",
    "\n",
    "Click the `Copy and Edit` button in the top-right corner.\n",
    "\n",
    "![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n",
    "\n",
    "This creates a private copy of the notebook just for you.\n",
    "\n",
    "**3. Run Code Cells**\n",
    "\n",
    "Once you have your copy, you can run code.\n",
    "\n",
    "Click the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n",
    "\n",
    "![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n",
    "\n",
    "Run the cells in order from top to bottom.\n",
    "\n",
    "**4. If You Get Stuck**\n",
    "\n",
    "To restart: Select `Factory reset` from the `Run` menu.\n",
    "\n",
    "For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 1: Setup\n",
    "\n",
    "### Install dependencies\n",
    "\n",
    "The Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n",
    "\n",
    "To install and use ADK in your own Python development environment outside of this course, you can do so by running:\n",
    "\n",
    "```\n",
    "pip install google-adk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Configure your Gemini API Key\n",
    "\n",
    "This notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n",
    "\n",
    "**1. Get your API key**\n",
    "\n",
    "If you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n",
    "\n",
    "**2. Add the key to Kaggle Secrets**\n",
    "\n",
    "Next, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n",
    "\n",
    "1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n",
    "2. Create a new secret with the label `GOOGLE_API_KEY`.\n",
    "3. Paste your API key into the \"Value\" field and click \"Save\".\n",
    "4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n",
    "\n",
    "**3. Authenticate in the notebook**\n",
    "\n",
    "Run the cell below to complete authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key successfully found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "if GOOGLE_API_KEY is not None:\n",
    "    print('Key successfully found')\n",
    "else:\n",
    "    print('missing Gemini Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai ChatGPT alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT Key found\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "\n",
    "OPENAI_API_BASE='http://localhost:11434/v1'\n",
    "OPENAI_API_KEY = os.getenv('CHATGPT_KEY')\n",
    "if OPENAI_API_KEY is not None:\n",
    "    print ('ChatGPT Key found')\n",
    "else:\n",
    "    print ('ChatGPT key missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import ADK components\n",
    "\n",
    "Now, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Section 2: Your first AI Agent with ADK\n",
    "\n",
    "### ü§î 2.1 What is an AI Agent?\n",
    "\n",
    "You've probably used an LLM like Gemini before, where you give it a prompt and it gives you a text response.\n",
    "\n",
    "`Prompt -> LLM -> Text`\n",
    "\n",
    "An AI Agent takes this one step further. An agent can think, take actions, and observe the results of those actions to give you a better answer.\n",
    "\n",
    "`Prompt -> Agent -> Thought -> Action -> Observation -> Final Answer`\n",
    "\n",
    "In this notebook, we'll build an agent that can take the action of searching Google. Let's see the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define your agent\n",
    "\n",
    "Now, let's build our agent. We'll configure an `Agent` by setting its key properties, which tell it what to do and how to operate.\n",
    "\n",
    "To learn more, check out the documentation related to [agents in ADK](https://google.github.io/adk-docs/agents/).\n",
    "\n",
    "These are the main properties we'll set:\n",
    "\n",
    "- **name** and **description**: A simple name and description to identify our agent.\n",
    "- **model**: The specific LLM that will power the agent's reasoning. We'll use \"gemini-2.5-flash-lite\".\n",
    "- **instruction**: The agent's guiding prompt. This tells the agent its goal is and how to behave.\n",
    "- **tools**: A list of [tools](https://google.github.io/adk-docs/tools/) that the agent can use. To start, we'll give it the `google_search` tool, which lets it find up-to-date information online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.models.lite_llm import LiteLlm\n",
    "\n",
    "openai_model = LiteLlm(model = \"openai/gpt-4o\")\n",
    "gemini_model = 'gemini-2.5-flash-lite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Root Agent defined.\n"
     ]
    }
   ],
   "source": [
    "root_agent = Agent(\n",
    "    name=\"helpful_assistant\",\n",
    "    model='gemini-2.5-flash-lite',\n",
    "    description=\"A simple agent that can answer general questions.\",\n",
    "    instruction=\"You are a helpful assistant. Use Google Search for current info or if unsure.\",\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Root Agent defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools.google_search_tool import GoogleSearchTool\n",
    "gs = GoogleSearchTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from google.adk.tools import google_search\n",
    "from google.adk.agents import LlmAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools.function_tool import FunctionTool\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firecrawl_search(query: str, limit: int = 5) -> dict:\n",
    "    import requests\n",
    "    FIRECRAWL_API_KEY = os.environ[\"FIRECRAWL_API_KEY\"]\n",
    "    resp = requests.post(\n",
    "        \"https://api.firecrawl.dev/search\",\n",
    "        headers={\"Authorization\": f\"Bearer {FIRECRAWL_API_KEY}\"},\n",
    "        json={\"query\": query, \"limit\": limit}\n",
    "    )\n",
    "    data = resp.json()\n",
    "    # Simplify results\n",
    "    return {\n",
    "        \"results\": [\n",
    "            {\"title\": item.get(\"title\"), \"url\": item.get(\"url\"), \"snippet\": item.get(\"description\")}\n",
    "            for item in data.get(\"data\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "searchtool = FunctionTool(firecrawl_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_agent = LlmAgent(\n",
    "    name=\"search_agent\",\n",
    "    model=openai_model,\n",
    "    instruction = \"You are a helpful assistant. Use Google Search for current info or if unsure.\",\n",
    "    description=\"A simple agent that can answer web-based questions\",\n",
    "    tools = [searchtool]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run your agent\n",
    "\n",
    "Now it's time to bring your agent to life and send it a query. To do this, you need a [`Runner`](https://google.github.io/adk-docs/runtime/), which is the central component within ADK that acts as the orchestrator. It manages the conversation, sends our messages to the agent, and handles its responses.\n",
    "\n",
    "**a. Create an `InMemoryRunner` and tell it to use our `root_agent`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runner created.\n"
     ]
    }
   ],
   "source": [
    "# running_agent = root_agent\n",
    "running_agent = openai_agent\n",
    "\n",
    "runner = InMemoryRunner(agent=running_agent)\n",
    "\n",
    "print(\"‚úÖ Runner created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Note that we are using the Python Runner directly in this notebook. You can also run agents using ADK command-line tools such as `adk run`, `adk web`, or `adk api_server`. To learn more, check out the documentation related to [runtime in ADK](https://google.github.io/adk-docs/runtime/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Now you can call the `.run_debug()` method to send our prompt and get an answer.**\n",
    "\n",
    "üëâ This method abstracts the process of session creation and maintenance and is used in prototyping. We'll explore \"what sessions are and how to create them\" on Day 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > What is Agent Development Kit from Google? What languages is the SDK available in?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Google search tool is not supported for model openai/gpt-4o",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\u001b[33m\"\u001b[39m\u001b[33mWhat is Agent Development Kit from Google? What languages is the SDK available in?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:1023\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1021\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1024\u001b[39m     user_id=user_id,\n\u001b[32m   1025\u001b[39m     session_id=session.id,\n\u001b[32m   1026\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1027\u001b[39m     run_config=run_config,\n\u001b[32m   1028\u001b[39m ):\n\u001b[32m   1029\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1030\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:443\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    436\u001b[39m       asyncio.create_task(\n\u001b[32m    437\u001b[39m           _run_compaction_for_sliding_window(\n\u001b[32m    438\u001b[39m               \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    439\u001b[39m           )\n\u001b[32m    440\u001b[39m       )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:427\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    421\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:653\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    652\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    654\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_append_event(event, is_live_call):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:416\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    415\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py:435\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    433\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:356\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    354\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    357\u001b[39m     last_event = event\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:375\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Preprocess before calling the LLM.\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    373\u001b[39m     \u001b[38;5;28mself\u001b[39m._preprocess_async(invocation_context, llm_request)\n\u001b[32m    374\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m invocation_context.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:493\u001b[39m, in \u001b[36mBaseLlmFlow._preprocess_async\u001b[39m\u001b[34m(self, invocation_context, llm_request)\u001b[39m\n\u001b[32m    486\u001b[39m tools = \u001b[38;5;28;01mawait\u001b[39;00m _convert_tool_union_to_tools(\n\u001b[32m    487\u001b[39m     tool_union,\n\u001b[32m    488\u001b[39m     ReadonlyContext(invocation_context),\n\u001b[32m    489\u001b[39m     agent.model,\n\u001b[32m    490\u001b[39m     multiple_tools,\n\u001b[32m    491\u001b[39m )\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m tool.process_llm_request(\n\u001b[32m    494\u001b[39m       tool_context=tool_context, llm_request=llm_request\n\u001b[32m    495\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PersonalProjects\\AgentCrashCourse\\.venv\\Lib\\site-packages\\google\\adk\\tools\\google_search_tool.py:72\u001b[39m, in \u001b[36mGoogleSearchTool.process_llm_request\u001b[39m\u001b[34m(self, tool_context, llm_request)\u001b[39m\n\u001b[32m     68\u001b[39m   llm_request.config.tools.append(\n\u001b[32m     69\u001b[39m       types.Tool(google_search=types.GoogleSearch())\n\u001b[32m     70\u001b[39m   )\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     73\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mGoogle search tool is not supported for model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_request.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     74\u001b[39m   )\n",
      "\u001b[31mValueError\u001b[39m: Google search tool is not supported for model openai/gpt-4o"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"What is Agent Development Kit from Google? What languages is the SDK available in?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a summary of ADK and its available languages in the response.\n",
    "\n",
    "### 2.4 How does it work?\n",
    "\n",
    "The agent performed a Google Search to get the latest information about ADK, and it knew to use this tool because:\n",
    "\n",
    "1. The agent inspects and is aware of which tools it has available to use.\n",
    "2. The agent's instructions specify the use of the search tool to get current information or if it is unsure of an answer.\n",
    "\n",
    "The best way to see the full, detailed trace of the agent's thoughts and actions is in the **ADK web UI**, which we'll set up later in this notebook.\n",
    "\n",
    "And we'll cover more detailed workflows for logging and observability later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ 2.5 Your Turn!\n",
    "\n",
    "This is your chance to see the agent in action. Ask it a question that requires current information.\n",
    "\n",
    "Try one of these, or make up your own:\n",
    "\n",
    "- What's the weather in London?\n",
    "- Who won the last soccer world cup?\n",
    "- What new movies are showing in theaters now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > How much wood would a woodchuck chuck if a woodchuck would chuck wood?\n",
      "helpful_assistant > This is a classic tongue twister and doesn't have a factual answer. The saying is meant to be a playful challenge for pronunciation, not a scientific inquiry into the wood-chucking capabilities of a woodchuck.\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"How much wood would a woodchuck chuck if a woodchuck would chuck wood?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > what will the weather be like tomorrow afternoon in London?\n",
      "helpful_assistant > Tomorrow afternoon in London, it is expected to be mostly cloudy with a chance of light rain. The temperature will be around 54¬∞F (12¬∞C), with a RealFeel¬Æ temperature of also 54¬∞F (12¬∞C). There will be a south-southwest wind at around 9 mph, with gusts up to 28 mph. The probability of precipitation is around 60%, with a 11% chance of thunderstorms. There is a chance of 0.17 inches of rain, with approximately 3 hours of precipitation. The cloud cover is expected to be around 82%.\n",
      "\n",
      "Another forecast for London suggests that tomorrow afternoon will be cloudy with showers, with temperatures around 14¬∞C.\n",
      "\n",
      "For the afternoon of Tuesday, November 11th, forecasts indicate continued cloudy weather with a chance of showers, with temperatures around 14¬∞C. Some sources also indicate light rain with a 25% chance of rain during the day.\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"what will the weather be like tomorrow afternoon in London?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíª Section 3: Try the ADK Web Interface\n",
    "\n",
    "### Overview\n",
    "\n",
    "ADK includes a built-in web interface for interactively chatting with, testing, and debugging your agents.\n",
    "\n",
    "<img width=\"1200\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/adk-web-ui.gif\" alt=\"ADK Web UI\" />\n",
    "\n",
    "To use the ADK web UI, you'll need to create an agent with Python files using the `adk create` command.\n",
    "\n",
    "Run the command below to generate a `sample-agent` folder that contains all the necessary files, including `agent.py` for your code, an `.env` file with your API key pre-configured, and an `__init__.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!adk create sample-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get your custom URL to access the ADK web UI in the Kaggle Notebooks environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run ADK web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!adk web --url_prefix {url_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can access the ADK dev UI using the link above.\n",
    "\n",
    "Once you open the link, you'll see the ADK web interface where you can ask your ADK agent questions.\n",
    "\n",
    "Note: This sample agent does not have any tools enabled (like Google Search). It is a basic agent designed specifically to let you explore the UI features.\n",
    "\n",
    "‚ÄºÔ∏è **IMPORTANT: DO NOT SHARE THE PROXY LINK** with anyone - treat it as sensitive data as it contains your authentication token in the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Congratulations!\n",
    "\n",
    "You've built and run your first agent with ADK! You've just seen the core concept of agent development in action.\n",
    "\n",
    "The big takeaway is that your agent didn't just *respond*‚Äîit **reasoned** that it needed more information and then **acted** by using a tool. This ability to take action is the foundation of all agent-based AI.\n",
    "\n",
    "**‚ÑπÔ∏è Note: No submission required!**\n",
    "\n",
    "This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n",
    "\n",
    "### üìö Learn More\n",
    "\n",
    "Refer to the following documentation to learn more:\n",
    "\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [ADK Quickstart for Python](https://google.github.io/adk-docs/get-started/python/)\n",
    "- [ADK Agents Overview](https://google.github.io/adk-docs/agents/)\n",
    "- [ADK Tools Overview](https://google.github.io/adk-docs/tools/)\n",
    "\n",
    "### üéØ Next Steps\n",
    "\n",
    "Ready for the next challenge? Continue to the next notebook to learn how to **architect multi-agent systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "| Authors |\n",
    "| --- |\n",
    "| [Kristopher Overholt](http://linkedin.com/in/koverholt) |"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CrashCourse",
   "language": "python",
   "name": "crashcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
